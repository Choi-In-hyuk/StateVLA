# StateVLA Configuration for LIBERO-Object
# Using Eagle2-VLM vision encoder and Qwen-7B-Chat language encoder

# ============= Data Configuration =============
data:
  data_directory: "/home/choi/StateVLA/data/libero/libero_object"
  demos_per_task: 50
  max_len_data: 260
  train_split: 0.9

# ============= Model Configuration =============
model:
  # Vision Encoder (Eagle2-VLM)
  image_encoder_type: "eagle2"  # eagle2, resnet, or siglip
  eagle2_model_name: "nvidia/Eagle2-1B"  # Eagle2-1B, Eagle2-2B, or Eagle2-9B
  freeze_vision_encoder: true
  latent_dim: 256

  # Language Encoder (Qwen)
  language_encoder_type: "qwen"  # qwen or clip
  qwen_model_name: "Qwen/Qwen2-7B-Instruct"  # Qwen2-7B-Instruct
  use_language_encoder: true
  freeze_language_encoder: true
  lang_emb_dim: 3584  # Qwen2-7B hidden size

  # CLIP fallback settings (if using clip encoder)
  clip_model_name: "ViT-B/32"

  # State Configuration (StateVLA specific)
  state_encoder_type: "mlp"  # mlp or cross_attention
  state_dim: 256
  state_predictor_layers: 4

  # Action Configuration
  action_dim: 7
  action_seq_len: 10
  obs_tok_len: 2

  # Policy Configuration
  policy_layers: 3
  policy_embed_dim: 256
  use_correction: true  # Enable residual correction

  # General
  dropout: 0.1

# ============= Training Configuration =============
training:
  batch_size: 32  # Reduced due to larger models
  num_epochs: 50  # Reduced from 2000 for practical training time
  learning_rate: 1.0e-4
  weight_decay: 0.05
  gradient_clip: 1.0

  # Loss weights
  action_loss_weight: 1.0
  state_loss_weight: 0.1

  # EMA
  enable_ema: true
  ema_decay_rate: 0.995

  # Data scaling
  enable_data_scaling: true
  data_scaler_type: "minmax"

  # Flow Matching
  sampling_steps: 4
  use_ln_timestep: false

  # Checkpointing
  save_interval: 5  # Save every 5 epochs for practical training
  checkpoint_dir: "checkpoints/libero_object"

  # Logging
  log_interval: 10
  use_wandb: false
  wandb_project: "statevla-libero"
  wandb_entity: null

# ============= Evaluation Configuration =============
evaluation:
  eval_during_training: true
  eval_interval: 100
  eval_num_rollouts: 5
  eval_max_steps: 400

# ============= Camera Configuration =============
cameras:
  names:
    - "agentview"
    - "eye_in_hand"
  image_size: 384  # Larger for Eagle2

# ============= Device Configuration =============
device: "cuda"  # cuda or cpu
seed: 42
