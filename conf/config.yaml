# StateVLA JEPA Configuration

# ============= Data Configuration =============
data:
  data_directory: "/path/to/your/data"  # Change this to your data path
  demos_per_task: 50
  max_len_data: 260
  train_split: 0.9

# ============= Model Configuration =============
model:
  # Tokenizer Configuration
  image_size: 224
  patch_size: 16  # 14x14 = 196 patches per image
  embed_dim: 256

  # Language
  lang_emb_dim: 512

  # Robot State
  robot_state_dim: 8  # joint_states(7) + gripper_states(1)

  # Mamba Encoder Configuration (State Space Model)
  encoder_depth: 12
  d_state: 16
  d_conv: 4
  expand: 2

  # JEPA Predictor Configuration
  predictor_embed_dim: 192
  predictor_depth: 6

  # Masking Configuration
  mask_ratio: 0.5
  masking_strategy: "modality_aware"  # modality_aware, random, block

  # State Configuration
  state_dim: 256

  # Action Configuration
  action_dim: 7
  action_seq_len: 10

  # Action Policy Configuration
  policy_layers: 3
  policy_embed_dim: 256

# ============= Training Configuration =============
training:
  batch_size: 64
  num_epochs: 2000
  learning_rate: 1.0e-4
  weight_decay: 0.05
  gradient_clip: 1.0

  # JEPA Loss Configuration
  jepa_loss_weight: 1.0
  action_loss_weight: 1.0

  # VICReg Regularization Weights
  variance_weight: 1.0
  covariance_weight: 0.04

  # EMA Target Encoder Configuration
  ema_momentum: 0.996
  ema_momentum_schedule: "cosine"  # constant or cosine

  # Learning Rate Scheduler
  use_lr_scheduler: false
  min_lr: 1.0e-6

  # Flow Matching
  sampling_steps: 4

  # Checkpointing
  save_interval: 100
  checkpoint_dir: "checkpoints"

  # Logging
  log_interval: 10

# ============= Camera Configuration =============
cameras:
  names:
    - "agentview"
    - "eye_in_hand"

# ============= Device Configuration =============
device: "cuda"  # cuda or cpu
seed: 42
