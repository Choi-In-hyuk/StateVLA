# StateVLA Two-Phase Training Configuration

# ============= Data Configuration =============
data:
  data_directory: "/home/choi/choi_ws/openvla/datasets/libero_object"
  demos_per_task: 50
  max_len_data: 260
  train_split: 0.9

# ============= Model Configuration =============
model:
  # Tokenizer Configuration
  image_size: 224
  patch_size: 16  # 14x14 = 196 patches per image
  embed_dim: 256

  # [추가됨] Pretrained Backbone Configuration (SigLIP & CLIP)
  use_pretrained_vision: true
  use_pretrained_language: true
  vision_model_name: "google/siglip-base-patch16-224"
  language_model_name: "ViT-B/32"
  freeze_vision: true
  freeze_language: true

  # Language
  lang_emb_dim: 512

  # Robot State
  robot_state_dim: 9  # joint_states(7) + gripper_states(2)

  # Mamba Encoder Configuration (State Space Model)
  encoder_depth: 12
  d_state: 16
  d_conv: 4
  expand: 2

  # Legacy JEPA Predictor Configuration
  predictor_embed_dim: 192
  predictor_depth: 6

  # Masking Configuration
  mask_ratio: 0.5
  masking_strategy: "modality_aware"

  # State Configuration
  state_dim: 256

  # Action Configuration
  action_dim: 7
  action_seq_len: 10

  # Action Policy Configuration
  policy_layers: 3
  policy_embed_dim: 256

# ============= Training Configuration =============
training:
  batch_size: 256
  num_epochs: 2000
  learning_rate: 1.0e-4
  weight_decay: 0.05
  gradient_clip: 1.0

  # Loss Weights
  jepa_loss_weight: 1.0
  action_loss_weight: 1.0

  # VICReg Regularization Weights
  variance_weight: 1.0
  covariance_weight: 0.04

  # EMA Target Encoder Configuration
  ema_momentum: 0.996
  ema_momentum_schedule: "cosine"

  use_lr_scheduler: false
  min_lr: 1.0e-6

  # Flow Matching
  sampling_steps: 4

  # Checkpointing
  save_interval: 100
  checkpoint_dir: "checkpoints"
  log_interval: 10

  # ---- Phase 1: Temporal JEPA ----
  phase1:
    num_epochs: 1000
    learning_rate: 1.0e-4
    temporal_predictor_hidden_dim: 512

  # ---- Phase 2: Flow Matching ----
  phase2:
    num_epochs: 1000
    learning_rate: 5.0e-5
    phase1_checkpoint: null

# ============= Camera & Device =============
cameras:
  names:
    - "agentview"
    - "eye_in_hand"

device: "cuda"
seed: 42